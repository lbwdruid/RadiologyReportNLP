{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "HUGGING_FACE_API_KEY = os.environ.get(\"HUGGING_FACE_API_KEY\")\n",
    "\n",
    "\n",
    "model_id = \"lmsys/fastchat-t5-3b-v1.0\"\n",
    "filenames = [\n",
    "        \"pytorch_model.bin\", \"added_tokens.json\", \"config.json\", \"generation_config.json\", \n",
    "        \"special_tokens_map.json\", \"spiece.model\", \"tokenizer_config.json\"\n",
    "]\n",
    "\n",
    "for filename in filenames:\n",
    "        downloaded_model_path = hf_hub_download(\n",
    "                    repo_id=model_id,\n",
    "                    filename=filename,\n",
    "                    token=HUGGING_FACE_API_KEY\n",
    "        )\n",
    "        # print(downloaded_model_path)\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, AutoModelForSeq2SeqLM\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_id, legacy=False)\n",
    "from transformers import T5Tokenizer\n",
    "\n",
    "local_model_dir = \"/home/lbwdruid/.cache/huggingface/hub/models--lmsys--fastchat-t5-3b-v1.0/snapshots/0b1da230a891854102d749b93f7ddf1f18a81024\"\n",
    "# tokenizer = T5Tokenizer.from_pretrained(local_model_dir)\n",
    "tokenizer = T5Tokenizer.from_pretrained(local_model_dir, legacy=False)\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_id)\n",
    "\n",
    "pipeline = pipeline(\"text2text-generation\", model=model, device=1, tokenizer=tokenizer, max_length=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C2-T5,T7-MidT9 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = '''I have a radiologist report, which includes where we should treat the patient on the Spine. Anatomically, the bones in the spine are labeled by these labels (these labels are in order, where C1 represents the top bone, and S5 represents the bottom bone): {C1, C2, C3, C4, C5, C6, C7, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, L1, L2, L3, L4, L5, S1, S2, S3, S4, S5}. Could you please help me to extract bone labels from the report below within the quotation marks, and keep the answer to only the labels that I provided? It may include a range of bones, please refer to the list that I provided, and find all bones. No explanation is needed, just the labels separated by commas please. List the bones explicitly one by one with out '-'.\n",
    "\n",
    "\"Plan to treat C2-T5, and T7-MidT9 diease.\"\n",
    "'''\n",
    "\n",
    "response = pipeline(prompt)[0]['generated_text']\n",
    "print (response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C2-T5,T7-T9 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = '''Human's bones in spine are labeled by these labels \n",
    "(these labels are in order, where C1 represents the top bone, and S5 represents the bottom bone): \n",
    "{C1, C2, C3, C4, C5, C6, C7, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, L1, L2, L3, L4, L5, S1, S2, S3, S4, S5}.\n",
    "The '-' in the following sentence represents a range of bones, the letters before it represent the top bone of the range,\n",
    "and the letters after it represent the bottom bone of the range.\n",
    "Remove '-' and print every bone in the range one by one explicitly.\n",
    "\n",
    "\"C2-T5,T7-T9\"\n",
    "'''\n",
    "\n",
    "response = pipeline(prompt)[0]['generated_text']\n",
    "print (response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am doing well, thank you for asking.\n"
     ]
    }
   ],
   "source": [
    "prompt = '''\n",
    "Well, how are you?\n",
    "'''\n",
    "\n",
    "response = pipeline(prompt)[0]['generated_text']\n",
    "print (response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
